{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9cce1c-d0e2-4d91-b9c8-bf1f6da9c07a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Pipeline Enhancements\n",
    "\n",
    "Let's go through one more development iteration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8a785a-aef3-428d-8236-dbaea0dcc337",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/forml/workspace/3-solution/forml-solution-avazuctr\n"
     ]
    }
   ],
   "source": [
    "%cd forml-solution-avazuctr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6ccf2-7369-4aaf-b337-92abb2b6d4a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Ensembling\n",
    "\n",
    "Instead of just the plain `LogisticRegression` used in our base model pipeline, we can combine multiple different classifiers using the [stacked ensembling](https://towardsdatascience.com/stacked-ensembles-improving-model-performance-on-a-higher-level-99ffc4ea5523) technique to further improve the performance. ForML already [comes with one possible operator](https://docs.forml.io/en/latest/_auto/forml.pipeline.ensemble.html) implementing this concept so let's try to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdeb0f0-567a-4b5c-943e-03a059ce5363",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Adding the Ensemble\n",
    "\n",
    "Add a basic model ensemble of **two classifiers** with just **two-fold crossvalidation** to the [avazuctr/pipeline.py](forml-solution-avazuctr/avazuctr/pipeline.py):\n",
    "\n",
    "1. Open the [avazuctr/pipeline.py](forml-solution-avazuctr/avazuctr/pipeline.py) component.\n",
    "2. Add all the required imports:\n",
    "```python\n",
    "from sklearn import model_selection\n",
    "\n",
    "from forml import project\n",
    "from forml.pipeline import ensemble, wrap\n",
    "\n",
    "with wrap.importer():\n",
    "    from category_encoders import TargetEncoder\n",
    "    from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e7970-7c0b-4374-aad5-8a2c0b22c037",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "3. Update it with the code below using the ensemble of `GradientBoostingClasifier` and `RandomForestClassifier`:\n",
    "```python\n",
    "CATEGORICAL_COLUMNS = ...  # Keep original\n",
    "\n",
    "STACK = ensemble.FullStack(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    crossvalidator=model_selection.StratifiedKFold(n_splits=2, shuffle=True, random_state=42),\n",
    ")\n",
    "\n",
    "PIPELINE = (\n",
    "    TargetEncoder(cols=CATEGORICAL_COLUMNS)\n",
    "    >> MinMaxScaler()\n",
    "    >> STACK\n",
    "    >> LogisticRegression(max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# Registering the pipeline\n",
    "project.setup(PIPELINE)\n",
    "```\n",
    "4. **SAVE THE [avazuctr/pipeline.py](forml-solution-avazuctr/avazuctr/pipeline.py) FILE!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9cf02-d5ba-4576-a5fe-186058176e46",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Evaluating the Change\n",
    "\n",
    "Let's now run the project evaluation to see whether this change was worth it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7e3c36-7869-4082-997f-4eb25923b24d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running eval\n",
      "0.3911373233919557\n"
     ]
    }
   ],
   "source": [
    "! forml project eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e705b78-7842-44af-ac85-f5096c1f5168",
   "metadata": {},
   "source": [
    "Excellent, this is an improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84c64dd-468a-4a19-b891-b5f6a77c0a40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! git add avazuctr/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f1cb1-9fad-49d9-99c0-b1cfe74f623e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Reviewing the Ensembling Task Graph\n",
    "Visualizing the ensembling task graph can help to understand the principle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cd280a-f976-4570-883a-23ae11107955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running train\n"
     ]
    }
   ],
   "source": [
    "! forml project train -R graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7487b1-7093-41cd-8e5f-e054625c9198",
   "metadata": {
    "tags": []
   },
   "source": [
    "_forml-solution-avazuctr/forml.dot.svg_:\n",
    "[![Ensembling Task Graph](./img/ensembling.svg)](./img/ensembling.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e1277-6c00-4b88-bc6d-2beaeb9b5c82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Balancing the Target Classes \n",
    "----------------------------\n",
    "\n",
    "As noticed during the [exploration](1-setup-and-exploration.ipynb), the target variable is highly imbalanced (417,963 in the negative class vs only 82,037 in the positive). This might be getting the model [biased towards the majority class](https://towardsdatascience.com/how-to-deal-with-imbalanced-data-34ab7db9b100).\n",
    "\n",
    "Let's try to use our [Balancer implemented previously](../2-tutorial/2-task-dependency-management.ipynb) to see if it brings any improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25170140-9dd3-4e96-9bcc-dbc422f50667",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Adding the Balancer\n",
    "\n",
    "Edit the [pyproject.toml](forml-solution-avazuctr/pyproject.toml) and add the new dependency of `imbalanced-learn==0.10.1`:\n",
    "\n",
    "1. Open the [pyproject.toml](forml-solution-avazuctr/pyproject.toml).\n",
    "2. Update it with the config below adding the new dependency of `imbalanced-learn==0.10.1`:\n",
    "```toml\n",
    "[project]\n",
    "name = \"forml-solution-avazuctr\"\n",
    "version = \"0.1\"\n",
    "dependencies = [\n",
    "    \"category-encoders==2.6.0\",\n",
    "    \"forml==0.93\",\n",
    "    \"imbalanced-learn==0.10.1 \",\n",
    "    \"openschema==0.7\",\n",
    "    \"pandas==2.0.1\",\n",
    "    \"scikit-learn==1.2.2\"\n",
    "]\n",
    "\n",
    "[tool.forml]\n",
    "package = \"avazuctr\"\n",
    "```\n",
    "3. **SAVE THE [pyproject.toml](forml-solution-avazuctr/pyproject.toml) FILE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5adb88-e607-48c6-a2f8-02516f0a7a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! git add pyproject.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4df1a-03f0-424d-a263-77318e4b6c42",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now, add the `Balancer` implementation to the [avazuctr/pipeline.py](forml-solution-avazuctr/avazuctr/pipeline.py):\n",
    "\n",
    "1. Open the [avazuctr/pipeline.py](forml-solution-avazuctr/avazuctr/pipeline.py) component.\n",
    "2. Add all the required imports:\n",
    "```python\n",
    "import typing\n",
    "\n",
    "from imblearn import over_sampling\n",
    "from sklearn import model_selection\n",
    "\n",
    "from forml import flow, project\n",
    "from forml.pipeline import ensemble, wrap\n",
    "\n",
    "with wrap.importer():\n",
    "    from category_encoders import TargetEncoder\n",
    "    from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945167f-6b2a-41cd-9568-2b6f30631f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "2. Add the `OverSampler` actor:\n",
    "```python\n",
    "@wrap.Actor.apply\n",
    "def OverSampler(\n",
    "    features, labels, *, random_state: typing.Optional[int] = None\n",
    "):\n",
    "    \"\"\"Stateless actor with two input and two output ports for oversampling the features/labels of the minor class.\"\"\"\n",
    "    return over_sampling.RandomOverSampler(\n",
    "        random_state=random_state\n",
    "    ).fit_resample(features, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e238ef-0aeb-4643-a6ef-be63029d8b6c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "3. Add the `Balancer` operator implementation:\n",
    "```python\n",
    "class Balancer(flow.Operator):\n",
    "    \"\"\"Balancer operator inserting the provided sampler into the ``train`` & ``label`` paths.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sampler: flow.Builder = OverSampler.builder(random_state=42),\n",
    "    ):\n",
    "        self._sampler = sampler\n",
    "\n",
    "    def compose(self, scope: flow.Composable) -> flow.Trunk:\n",
    "        left = scope.expand()\n",
    "        sampler = flow.Worker(self._sampler, 2, 2)\n",
    "        sampler[0].subscribe(left.train.publisher)\n",
    "        new_features = flow.Future()\n",
    "        new_features[0].subscribe(sampler[0])\n",
    "        sampler[1].subscribe(left.label.publisher)\n",
    "        new_labels = flow.Future()\n",
    "        new_labels[0].subscribe(sampler[1])\n",
    "        return left.use(\n",
    "            train=left.train.extend(tail=new_features),\n",
    "            label=left.label.extend(tail=new_labels),\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5ec06-1168-4569-a02c-d6fdd3a1987f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "4. Insert the `Balancer` into the operator right after the `TargetEncoder`:\n",
    "```python\n",
    "CATEGORICAL_COLUMNS = ... # Keep original\n",
    "STACK = ... # Keep original\n",
    "\n",
    "PIPELINE = (\n",
    "    TargetEncoder(cols=CATEGORICAL_COLUMNS)\n",
    "    >> Balancer()    # Inserting the Balancer\n",
    "    >> MinMaxScaler()\n",
    "    >> STACK\n",
    "    >> LogisticRegression(warm_start=True, max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "# Registering the pipeline\n",
    "project.setup(PIPELINE)\n",
    "```\n",
    "5. **SAVE THE [avazuctr/pipeline.py](forml-solution-avazuctr/avazuctr/pipeline.py) FILE!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2c12e-044f-45f9-8a8e-8916d02c5073",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Evaluating the Change\n",
    "Let's quickly confirm the data is now balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6985acf8-7948-48ff-90a7-03cdfe0cd24f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click\n",
       "0    417919\n",
       "1    417919\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from forml import project\n",
    "from avazuctr import pipeline\n",
    "PROJECT = project.open(path=\".\", package=\"avazuctr\")\n",
    "PROJECT.components.source.bind(\n",
    "    pipeline.Balancer()\n",
    ").launcher.train().labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84adc893-2398-4d7f-b0c0-be83f9aedbe0",
   "metadata": {},
   "source": [
    "Good, let's kick off the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42fe3777-6efc-46ee-a9c3-d84241b1e022",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running eval\n",
      "0.38634029551291765\n"
     ]
    }
   ],
   "source": [
    "! forml project eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b200fbc8-ac77-4f5e-a7a1-ab924bc60b9f",
   "metadata": {},
   "source": [
    "That's another improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70856fc1-209d-4832-a830-fed010ffb168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! git add avazuctr/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d64cc-4529-4866-945d-7f2894fae435",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Reviewing the Final Task Graph\n",
    "To visualize the the final task graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1aa4ef-c64e-412f-96ba-00e742553c76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running train\n"
     ]
    }
   ],
   "source": [
    "! forml project train -R graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2532f-b63b-4034-8552-2ae34f7650c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "_forml.dot.svg_:\n",
    "[![Final Task Graph](img/enhanced.svg)](img/enhanced.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897237cb-7ba7-479d-a43d-f70d5337ac43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Adding the Balancer Unit Test\n",
    "\n",
    "Let's also add the [Balancer unit test implemented previously](../2-tutorial/2-task-dependency-management.ipynb) to the project tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0fbbea-c0cc-4515-8915-879598ef6b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! touch tests/test_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce72726-7689-46c7-bdcc-951b0a0e87be",
   "metadata": {
    "tags": []
   },
   "source": [
    "Edit the created [test_pipeline.py](forml-solution-avazuctr/tests/test_pipeline.py) and implement the unit test:\n",
    "\n",
    "1. Open the [test_pipeline.py](forml-solution-avazuctr/tests/test_pipeline.py).\n",
    "2. Update it with the code below providing the `TestBalancer` unit test implementation:\n",
    "```python\n",
    "from forml import testing\n",
    "from avazuctr import pipeline\n",
    "\n",
    "class TestBalancer(testing.operator(pipeline.Balancer)):\n",
    "    \"\"\"Balancer unit tests.\"\"\"\n",
    "\n",
    "    default_oversample = (\n",
    "        testing.Case()\n",
    "        .train([[1], [1], [0]], [1, 1, 0])\n",
    "        .returns([[1], [1], [0], [0]], labels=[1, 1, 0, 0])\n",
    "    )\n",
    "```\n",
    "3. **SAVE THE [test_pipeline.py](forml-solution-avazuctr/tests/test_pipeline.py) FILE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e23609-4c65-4d54-b6c8-3635c1d9175f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! git add tests/test_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d0887-a879-412b-be8b-e4fca12a92ea",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let's trigger the project tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e458ba1-ffe8-4b1a-ac6d-8878257dc56e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    result = self.execute(*args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/forml/flow/_code/target/user.py\", line 196, in execute\n",
      "    return self.action(self.builder(), *args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/forml/flow/_code/target/user.py\", line 150, in __call__\n",
      "    result = actor.apply(*args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/forml/pipeline/wrap/_actor.py\", line 166, in apply\n",
      "    return self.Apply(*features, **self._kwargs)\n",
      "  File \"/opt/forml/workspace/3-solution/forml-solution-avazuctr/avazuctr/source.py\", line 11, in TimeExtractor\n",
      "    assert \"hour\" in features.columns, \"Missing column: hour\"\n",
      "AssertionError: Missing column: hour\n",
      "ok\n",
      "test_valid_extraction (tests.test_source.TestTimeExtractor)\n",
      "Test of Valid Extraction ... ok\n",
      "test_default_oversample (tests.test_pipeline.TestBalancer)\n",
      "Test of Default Oversample ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 5.571s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "! forml project test 2>&1 | tail -n 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
